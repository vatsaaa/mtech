{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatsaaa/mtech/blob/main/semester_3/DML_Group99_Assignment1_Year2Sem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group members\n",
        "<table width=\"100%\">\n",
        "  <tr>\n",
        "    <th width=\"25%\">Name</th>\n",
        "    <th width=\"40%\">Email</th>\n",
        "    <th width=\"20%\">Student ID</th>\n",
        "    <th width=\"15%\">Contribution</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>G. Ankur Vatsa</td>\n",
        "    <td>2023aa05727@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05727</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Aziz Hussain Sharif</td>\n",
        "    <td>2023ab05092@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023ab05092</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Mukund Kumar</td>\n",
        "    <td>2023aa05458@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05458</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Tarush Jaiswal</td>\n",
        "    <td>2023aa05769@wilp.bits-pilani.ac.in</td>\n",
        "    <td>2023aa05769</td>\n",
        "    <td>100%</td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "cEsOGH_S-TuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explore and implement vertical and horizontal partitioning of AI models, applying them to a wireless network optimization problem.**\n",
        "\n",
        "# Part 1\n",
        "1. **Define vertical partitioning and horizontal partitioning in the context of AI models.**"
      ],
      "metadata": {
        "id": "fHPnxfZozE_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vertical and Horizontal Partitioning in AI Models\n",
        "\n",
        "In the context of AI models, partitioning refers to dividing the components, processes, or data of a model to optimize specific aspects of its design, training, deployment, or performance. Vertical and horizontal partitioning, concepts borrowed from database systems, can be applied to AI models in different ways."
      ],
      "metadata": {
        "id": "W1Vn1jxLy_B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertical Partitioning\n",
        "Vertical partitioning involves dividing the features or tasks of an AI model into separate, specialized components. This type of partitioning allows different parts of a model to focus on different tasks or subsets of features.\n",
        "\n",
        "### Key Characteristics:\n",
        "\n",
        "- **Feature-based Division:** The input feature set is divided, and different models or sub-models handle distinct subsets of features.\n",
        "- **Task Segmentation:** Different tasks (e.g., classification, regression, prediction, etc.) are handled by separate sub-models.\n",
        "- **Interdependence:** The partitions may interact, with outputs of one partition feeding into another.\n",
        "\n",
        "### Advantages:\n",
        "- **Specialization:** Each sub-model can be optimized for a specific subset of features or tasks.\n",
        "- **Modularity:** Easier debugging, training, and updating of individual components.\n",
        "- **Scalability:** Enables distributed or parallel processing of tasks/features.\n",
        "\n",
        "### Challenges\n",
        "- **Integration Overhead:** Combining outputs from different partitions can be complex.\n",
        "- **Feature Overlap:** Shared features may require duplication or additional synchronization efforts.\n",
        "\n",
        "### Example in Wireless Network Optimization:\n",
        "- **Partitioning by Functionality:** One model focuses on optimizing resource allocation (e.g., bandwidth), while another handles interference management.\n",
        "- **Feature Segmentation:** Features like user mobility patterns, signal strength, and device capabilities are split across different models."
      ],
      "metadata": {
        "id": "CGaUHs-B0Lrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Horizontal Partitioning\n",
        "Horizontal partitioning divides the data processed by an AI model based on specific criteria such as time, geography, or user segments. All partitions use the same model structure but are trained and deployed separately on different data subsets.\n",
        "\n",
        "### Key Characteristics\n",
        "- **Data-based Division:** Input data is divided into disjoint or overlapping subsets.\n",
        "- **Uniform Model Structure:** The same AI model architecture is applied to all subsets.\n",
        "- **Independent Processing:** Each partition can be trained or deployed independently.\n",
        "\n",
        "### Advantages\n",
        "- **Localized Optimization:** Models trained on specific data subsets can adapt to local patterns or needs.\n",
        "- **Improved Efficiency:** Smaller datasets reduce training time and resource requirements.\n",
        "- **Fault Tolerance:** Failures in one partition do not affect others.\n",
        "\n",
        "### Challenges:\n",
        "- **Data Balancing:** Ensuring uniform data distribution across partitions can be challenging.\n",
        "- **Consistency:** Aligning outputs or behaviors across partitions might require additional coordination.\n",
        "- **Overhead in Deployment:** Managing multiple partitions increases deployment complexity.\n",
        "\n",
        "### Example in Wireless Network Optimization\n",
        "- **Geographic Partitioning:** The network is divided into regions (e.g., urban vs. rural), and models are trained separately for each region to handle localized traffic patterns.\n",
        "- **User Segmentation:** Users are grouped by device type or usage behavior, and separate models are trained for each group."
      ],
      "metadata": {
        "id": "SITd2UnA0HD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertical and Horizontal Partitioning applied to Wireless Network Optimization\n",
        "Wireless network optimization is a multi-faceted problem involving tasks such as spectrum management, power control, traffic scheduling, and resource allocation. Both vertical and horizontal partitioning can play critical roles in designing efficient AI-based solutions.\n",
        "\n",
        "### Approach:\n",
        "1. **Problem Definition**\n",
        "- Identify optimization goals (e.g., maximize throughput, minimize latency, reduce energy consumption).\n",
        "- Determine key features and data subsets (e.g., signal strength, user mobility patterns, interference levels).\n",
        "2. **Choose the Partitioning Strategy**\n",
        "- **Vertical Partitioning:** Divide the problem into subtasks such as spectrum allocation, interference management, and user scheduling. Assign each subtask to a dedicated AI model or sub-model.\n",
        "- **Horizontal Partitioning:** Segment the data based on geography, time, or user demographics. Train the same model separately for each segment.\n",
        "3. **Implementation**\n",
        "- Use modular AI architectures (e.g., multi-task neural networks for vertical partitioning or federated learning for horizontal partitioning).\n",
        "- Leverage distributed training frameworks for parallel processing of partitions.\n",
        "4. **Optimization and Deployment**\n",
        "- Test individual partitions for performance and accuracy.\n",
        "- Integrate outputs from vertical partitions or align results from horizontal partitions.\n",
        "- Deploy partitions in a distributed manner across network nodes.\n",
        "5. **Evaluate Performance**\n",
        "- Monitor improvements in key metrics (e.g., throughput, latency, fairness).\n",
        "- Iterate on partitioning strategies based on real-world feedback."
      ],
      "metadata": {
        "id": "vjTLSXmq1llN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Vertical and horizontal partitioning are powerful techniques to enhance the scalability, efficiency, and performance of AI models, especially for complex problems like wireless network optimization. By combining these approaches strategically, you can build modular, adaptive, and efficient AI solutions tailored to specific tasks and data characteristics."
      ],
      "metadata": {
        "id": "61knkfF42d2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1\n",
        "2. **Compare the advantages and disadvantages of these partitioning methods, focusing on computational efficiency, scalability, and real-world application in wireless networks (consider any dataset that is easily available and understandable for an undergraduate student).**"
      ],
      "metadata": {
        "id": "MROI4-Wt4_wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for Wireless Networks\n",
        "The **Telecom Italia Big Data Challenge** provides a rich context and apply these methods. The dataset includes features like user mobility, signal strength, and call records, which are understandable and manageable for undergraduates.\n",
        "\n",
        "- **Vertical Partitioning:** Separate models can be created for analyzing signal strength, user mobility patterns, and call records independently, followed by integrating results for network optimization.\n",
        "- **Horizontal Partitioning:** Data can be partitioned geographically (e.g., by city or region), and identical models can be trained on each subset to optimize local network performance."
      ],
      "metadata": {
        "id": "kthaE7rM5SPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Telecom Italia Big Data Challenge dataset** is a comprehensive collection of telecommunications data from the city of Milan and the Province of Trentino, Italy, covering the period from November to December 2013. The dataset includes anonymized, geo-referenced records of SMS, call, and internet activities, making it valuable for research in urban computing, human mobility, and network optimization.\n",
        "\n",
        "## Accessing the Dataset:\n",
        "\n",
        "1. **Harvard Dataverse**\n",
        "- **Telecommunications Data:** The primary dataset is available on [Harvard Dataverse](https://www.nature.com/articles/sdata201555). It includes daily records of telecommunication activities.\n",
        "- **Milan Grid GeoJSON:** The spatial grid defining Milan's area is available, here.\n",
        "\n",
        "2. **Kaggle**\n",
        "- **Mobile Phone Activity in a City:** A subset of the dataset focusing on Milan is hosted on Kaggle, [here](https://www.kaggle.com/datasets/ocanaydin/italian-telecom-data-2013-1week) and [here](https://www.kaggle.com/code/ijfezika/mobile-phone-activity-exploratory-analysis). This subset of data is convenient for exploratory data analysis and modeling.\n",
        "\n",
        "3. **GitHub**\n",
        "- **Milan Telecom Data Modeling:** A GitHub repository contains scripts and additional resources for analyzing the Milan telecommunication data, [here](https://github.com/arunasubbiah/milan-telecom-data-modeling) and [here](https://github.com/pjsudharshan/Big_Data_Time_Series_Analysis).\n",
        "\n",
        "## Dataset Contents:\n",
        "- **Telecommunication Activity:** Records of SMS, call, and internet usage aggregated over time intervals and spatial grids.\n",
        "- **Spatial Information:** Geo-referenced grid data dividing Milan into approximately 235×235 meter cells.\n",
        "- **Temporal Coverage:** Data spans from November 1, 2013, to January 1, 2014, with daily files.\n",
        "\n",
        "## Data Usage Considerations:\n",
        "- **Licensing:** The dataset is released under the Open Database License (ODbL), allowing for use, modification, and sharing under the same license.\n",
        "- **Data Size:** The full dataset is substantial, with some files being large. Ensure adequate storage and processing capabilities.\n",
        "- **Anonymization:** All personal identifiers have been removed to protect privacy. Data is aggregated to spatial and temporal levels to prevent re-identification.\n",
        "\n",
        "## Applications:\n",
        "\n",
        "This dataset is suitable for various analyses, including:\n",
        "\n",
        "- **Urban Mobility Analysis:** Studying movement patterns within the city.\n",
        "- **Network Optimization:** Improving telecommunication infrastructure based on usage patterns.\n",
        "- **Social Dynamics:** Understanding how different areas interact based on communication data.\n",
        "\n",
        "By utilizing these resources, one can conduct comprehensive analyses of telecommunication patterns in Milan, contributing to fields such as urban planning, network optimization, and data science education."
      ],
      "metadata": {
        "id": "ptRBCD2b7Nb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Vertical and Horizontal Partitioning in AI Models\n",
        "\n",
        "To compare vertical and horizontal partitioning, we will evaluate them based on **computational efficiency, scalability,** and their **real-world application in wireless networks**. The analysis will also consider datasets suitable for undergraduate students, such as those from the Telecom Italia Big Data Challenge or synthetic datasets generated using Python libraries like Scikit-learn."
      ],
      "metadata": {
        "id": "SoIwsCDz8msw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Computational Efficiency\n",
        "## Vertical Partitioning\n",
        "\n",
        "### Advantages:\n",
        "- **Task Specialization:** Sub-models handle smaller, specific tasks, reducing the computational load per task.\n",
        "- **Parallelization:** Different tasks or feature subsets can be processed in parallel by separate sub-models.\n",
        "- **Optimized Resource Allocation:** Allows for resource optimization at the task level (e.g., allocating GPUs to compute-intensive tasks).\n",
        "\n",
        "### Disadvantages:\n",
        "- **Integration Overhead:** Combining outputs of sub-models may add extra computation, especially for tasks with high interdependencies.\n",
        "- **Underutilized Resources:** In cases where tasks are not balanced in complexity, some partitions may underutilize resources.\n",
        "\n",
        "## Horizontal Partitioning\n",
        "\n",
        "### Advantages:\n",
        "- **Localized Training:** Smaller datasets per partition result in faster training times and reduced computational requirements.\n",
        "- **Independent Processing:** Each data partition can be trained or deployed independently, enabling distributed computation.\n",
        "\n",
        "### Disadvantages:\n",
        "- **Redundancy:** Using identical models across partitions increases storage and deployment overhead.\n",
        "- **Cross-Partition Coordination:** Aligning outputs across partitions (e.g., ensuring fairness in resource allocation) can require additional computational effort."
      ],
      "metadata": {
        "id": "Oo_V6q3n8xf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Scalability\n",
        "## Vertical Partitioning\n",
        "\n",
        "### Advantages:\n",
        "- **Scalable Task Handling:** Adding new tasks or feature subsets is straightforward by introducing new sub-models.\n",
        "- **Modular Design:** The modular nature allows the system to scale horizontally by adding resources for specific tasks.\n",
        "\n",
        "### Disadvantages:\n",
        "- **Complexity Growth:** As the number of tasks or features grows, the interdependencies between partitions can become harder to manage.\n",
        "- **Task-Specific Scaling:** Scaling is limited by the inherent complexity of individual tasks.\n",
        "\n",
        "## Horizontal Partitioning\n",
        "\n",
        "### Advantages:\n",
        "- **Data Partitioning:** Easily scalable for large datasets by increasing the number of partitions.\n",
        "- **Distributed Training:** Ideal for environments like cloud platforms, where multiple nodes can train partitions simultaneously.\n",
        "\n",
        "### Disadvantages:\n",
        "- **Partition Balancing:** Ensuring that each partition has sufficient and balanced data for training can be challenging.\n",
        "- **Model Duplication:** The same model architecture must be scaled for all partitions, which could lead to inefficiencies."
      ],
      "metadata": {
        "id": "29ZfGwY-9Lz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Real-World Application in Wireless Networks\n",
        "## Vertical Partitioning\n",
        "\n",
        "### Advantages:\n",
        "- **Task-Specific Models:** Optimizes individual tasks like spectrum management, power control, or interference mitigation.\n",
        "- **Cross-Domain Adaptability:** Features related to different network layers (e.g., physical, MAC, and network layers) can be processed separately and integrated.\n",
        "\n",
        "### Disadvantages:\n",
        "- **Integration Complexity:** Requires careful integration of outputs for a cohesive optimization strategy.\n",
        "- **High Initial Setup:** Partitioning tasks and features requires domain expertise and a thorough understanding of the problem.\n",
        "\n",
        "## Horizontal Partitioning\n",
        "\n",
        "### Advantages:\n",
        "- **Localized Optimization:** Models can be trained on regional datasets, making them suitable for geographic or demographic-specific optimization.\n",
        "- **Fault Tolerance:** If one partition fails, others can continue functioning, which is critical for decentralized systems.\n",
        "\n",
        "### Disadvantages:\n",
        "- **Fragmented Knowledge:** Each model may learn localized patterns, missing broader global trends unless explicitly accounted for.\n",
        "- **Dataset Dependency:** Requires well-structured and labeled data for effective partitioning, which may not always be available."
      ],
      "metadata": {
        "id": "EMyfxMB29y1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tabulated Advantages and Disadvantages\n",
        "<table width=\"100%\">\n",
        "  <tr>\n",
        "    <th>Criterion</th>\n",
        "    <th>Vertical Partitioning</th>\n",
        "    <th>Horizontal Partitioning</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><b>Computational Efficiency</b></td>\n",
        "    <td>Specialized models reduce task complexity, but integration overhead can increase.</td>\n",
        "    <td>Localized training speeds up computation, but redundancy adds overhead.</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><b>Scalability</b></td>\n",
        "    <td>Scales well for task-specific optimizations but struggles with inter-task dependencies.</td>\n",
        "    <td>Highly scalable with distributed data but requires balanced partitions.</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><b>Real-World Application</b></td>\n",
        "    <td>Suitable for task-based optimization in multi-layer networks.</td>\n",
        "    <td>Best for localized or regional optimization with decentralized systems.</td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "0ua9cf0i_NPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation\n",
        "For wireless network optimization:\n",
        "\n",
        "- Use vertical partitioning when solving complex, multi-faceted problems that benefit from task-specific specialization (e.g., resource allocation vs. interference management).\n",
        "- Use horizontal partitioning when optimizing for regional or localized network performance (e.g., rural vs. urban network needs).\n",
        "\n",
        "By combining these approaches (e.g., vertical partitioning for tasks within each horizontal data partition), one can achieve a balanced solution that maximizes computational efficiency and scalability while addressing real-world challenges."
      ],
      "metadata": {
        "id": "NGOHGtDOAUxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Practical Implementation (60 Points)\n",
        "You are given a pre-trained model for predicting network latency and a dataset with the\n",
        "following attributes:\n",
        "- **Tower ID**\n",
        "- **Signal Strength (dBm)**\n",
        "- **Network Traffic (MB)**\n",
        "- **Latency (ms)**\n",
        "- **User Count**\n",
        "- **Device Type**\n",
        "\n",
        "## **Tasks:**\n",
        "\n",
        "### 1. **Vertical Partitioning (30 Points)**\n",
        "- Split the original model into two sub-models:\n",
        " - **Model A:** Processes features related to the network (e.g., Signal\n",
        "Strength, Network Traffic).\n",
        " - **Model B:** Processes features related to user behavior (e.g., User Count, Device Type).\n",
        "\n",
        "- Combine the outputs of **Model A** and **Model B** to predict network latency.\n",
        "- Compare the performance of the partitioned model to the original monolithic model using metrics like accuracy and latency prediction error.\n",
        "\n",
        "### 2. **Horizontal Partitioning (30 Points)**\n",
        "- Divide the dataset into two subsets based on geographic categories:\n",
        " - **Subset 1:** Urban cell towers.\n",
        " - **Subset 2:** Rural cell towers.\n",
        "- Train separate models for each subset and compare their performance to a single model trained on the entire dataset.\n",
        "- Provide insights into the benefits of horizontal partitioning in this scenario."
      ],
      "metadata": {
        "id": "fDB6PbTlEnSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vertical Partitioning"
      ],
      "metadata": {
        "id": "ArOrSBvEGGU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "import random\n",
        "import joblib"
      ],
      "metadata": {
        "id": "pa0rjdQDF-8j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate data\n",
        "def generate_network_data(num_samples=200000):\n",
        "  \"\"\"\n",
        "  Generates a synthetic dataset for network performance prediction.\n",
        "\n",
        "  Args:\n",
        "    num_samples: The number of samples to generate.\n",
        "\n",
        "  Returns:\n",
        "    A list of dictionaries, where each dictionary represents a single data sample.\n",
        "  \"\"\"\n",
        "\n",
        "  data = []\n",
        "  for _ in range(num_samples):\n",
        "    sample = {}\n",
        "\n",
        "    # Generate random values within specified ranges\n",
        "    sample['Tower ID'] = random.randint(1001, 50000)\n",
        "    sample['Signal Strength (dBm)'] = round(random.uniform(-95, -50), 2)  # Decimal signal strength\n",
        "    sample['Network Traffic (MB)'] = round(random.uniform(100, 1500), 2)  # Decimal network traffic\n",
        "    sample['User Count'] = random.randint(1, 50)\n",
        "    sample['Device Type'] = random.randint(1, 5)  # 5 device types\n",
        "    sample['Region'] = random.choice(['Urban', 'Rural'])\n",
        "\n",
        "    # Calculate latency with region-specific adjustments and noise\n",
        "    base_latency = 10 + 0.05 * sample['Network Traffic (MB)'] - 0.1 * sample['Signal Strength (dBm)']\n",
        "    if sample['Region'] == 'Urban':\n",
        "      base_latency += 5\n",
        "    else:\n",
        "      base_latency += 10\n",
        "    sample['Latency (ms)'] = int(max(base_latency + random.gauss(0, 5), 10))  # Integer latency\n",
        "\n",
        "    data.append(sample)\n",
        "\n",
        "  return data\n",
        "\n",
        "# Generate 200,000 samples\n",
        "synthetic_data = generate_network_data(num_samples=200000)\n",
        "\n",
        "# Print the first 5 samples\n",
        "for sample in synthetic_data[:5]:\n",
        "  print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUtH_hiVaS7y",
        "outputId": "e3ac48e9-5e0c-4d65-8b8f-38c7e73829ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Tower ID': 41138, 'Signal Strength (dBm)': -90.57, 'Network Traffic (MB)': 1025.13, 'User Count': 13, 'Device Type': 5, 'Region': 'Rural', 'Latency (ms)': 80}\n",
            "{'Tower ID': 5551, 'Signal Strength (dBm)': -90.52, 'Network Traffic (MB)': 928.19, 'User Count': 7, 'Device Type': 4, 'Region': 'Rural', 'Latency (ms)': 75}\n",
            "{'Tower ID': 3015, 'Signal Strength (dBm)': -72.56, 'Network Traffic (MB)': 989.84, 'User Count': 8, 'Device Type': 2, 'Region': 'Urban', 'Latency (ms)': 65}\n",
            "{'Tower ID': 40743, 'Signal Strength (dBm)': -86.3, 'Network Traffic (MB)': 661.61, 'User Count': 37, 'Device Type': 3, 'Region': 'Urban', 'Latency (ms)': 60}\n",
            "{'Tower ID': 28271, 'Signal Strength (dBm)': -69.63, 'Network Traffic (MB)': 333.71, 'User Count': 1, 'Device Type': 2, 'Region': 'Rural', 'Latency (ms)': 51}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a sample dataset with features relevant to the task.\n",
        "Columns:\n",
        "- **Signal Strength (dBm)** and **Network Traffic (MB)** represent network-related features.\n",
        "- **User Count** and **Device Type** represent user-related features.\n",
        "- **Latency (ms)** is the target variable that we aim to predict.\n"
      ],
      "metadata": {
        "id": "nciOlQogGtV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load dataset and build the model/s\n",
        "data = pd.DataFrame(synthetic_data)\n",
        "\n",
        "# Split dataset into features and target\n",
        "X = data.drop(['Latency (ms)'], axis=1)\n",
        "y = data['Latency (ms)']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "exEcttV9F_1W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Vertical Partitioning\n",
        "## Model A: Network-related features\n",
        "network_features = ['Signal Strength (dBm)', 'Network Traffic (MB)']\n",
        "X_train_A = X_train[network_features]\n",
        "X_test_A = X_test[network_features]\n",
        "\n",
        "model_A = RandomForestRegressor(random_state=42)\n",
        "model_A.fit(X_train_A, y_train)\n",
        "\n",
        "## Model B: User-related features\n",
        "user_features = ['User Count', 'Device Type']\n",
        "X_train_B = X_train[user_features]\n",
        "X_test_B = X_test[user_features]\n",
        "\n",
        "model_B = RandomForestRegressor(random_state=42)\n",
        "model_B.fit(X_train_B, y_train)\n",
        "\n",
        "## TODO: Saving models is not required, get rid of this\n",
        "# Save Model A\n",
        "joblib.dump(model_A, 'model_Av.joblib')\n",
        "\n",
        "# Save Model B\n",
        "joblib.dump(model_B, 'model_Bv.joblib')"
      ],
      "metadata": {
        "id": "N3gt_DK3GBlV",
        "outputId": "6b4cb5d6-e110-497c-ddc7-2b0fc36f9faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Outputs and Performance Evaluation\n",
        "\n",
        "The predictions from both models are averaged and the **Mean Absolute Error (MAE)** measures the combined model’s performance.\n"
      ],
      "metadata": {
        "id": "ylenSChVHV6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Combine outputs of Model A and Model B\n",
        "predictions_A = model_A.predict(X_test_A)\n",
        "predictions_B = model_B.predict(X_test_B)\n",
        "combined_predictions = (predictions_A + predictions_B) / 2\n",
        "\n",
        "## Evaluate performance\n",
        "mae_combined = mean_absolute_error(y_test, combined_predictions)\n",
        "print(f'Mean Absolute Error (Combined Model): {mae_combined}')"
      ],
      "metadata": {
        "id": "r1aPHByTGExO",
        "outputId": "464e95e8-da6c-4bd6-d1dd-da391dd1adfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (Combined Model): 9.676951661156586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Horizontal Partitioning"
      ],
      "metadata": {
        "id": "42PR85WHGI2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "import random\n",
        "import joblib"
      ],
      "metadata": {
        "id": "aDpwMmJhGLVA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load dataset\n",
        "data = pd.DataFrame(synthetic_data)\n",
        "\n",
        "## Split dataset into urban and rural subsets\n",
        "urban_data = data[data['Region'] == 'Urban']\n",
        "rural_data = data[data['Region'] == 'Rural']"
      ],
      "metadata": {
        "id": "KAp3lDkIGRc9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train model for urban subset\n",
        "X_urban = urban_data.drop(['Latency (ms)', 'Region'], axis=1)\n",
        "y_urban = urban_data['Latency (ms)']\n",
        "X_train_urban, X_test_urban, y_train_urban, y_test_urban = train_test_split(X_urban, y_urban, test_size=0.3, random_state=42)\n",
        "\n",
        "model_urban = RandomForestRegressor(random_state=42)\n",
        "model_urban.fit(X_train_urban, y_train_urban)\n",
        "predictions_urban = model_urban.predict(X_test_urban)\n",
        "\n",
        "mae_urban = mean_absolute_error(y_test_urban, predictions_urban)\n",
        "print(f'Mean Absolute Error (Urban Model): {mae_urban}')"
      ],
      "metadata": {
        "id": "QL30hxmVGT4r",
        "outputId": "5244e1c5-b5c3-4f47-b148-d8ec3d0937a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (Urban Model): 4.144527648234511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train model for rural subset\n",
        "X_rural = rural_data.drop(['Latency (ms)', 'Region'], axis=1)\n",
        "y_rural = rural_data['Latency (ms)']\n",
        "X_train_rural, X_test_rural, y_train_rural, y_test_rural = train_test_split(X_rural, y_rural, test_size=0.3, random_state=42)\n",
        "\n",
        "model_rural = RandomForestRegressor(random_state=42)\n",
        "model_rural.fit(X_train_rural, y_train_rural)\n",
        "predictions_rural = model_rural.predict(X_test_rural)\n",
        "\n",
        "mae_rural = mean_absolute_error(y_test_rural, predictions_rural)\n",
        "print(f'Mean Absolute Error (Rural Model): {mae_rural}')\n"
      ],
      "metadata": {
        "id": "TMCKhFhTGVlR",
        "outputId": "6e08c543-0183-4040-8fd7-2cb88a8b5166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (Rural Model): 4.152399519695808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluate a single model on the entire dataset\n",
        "X = data.drop(['Latency (ms)', 'Region'], axis=1)\n",
        "y = data['Latency (ms)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model_single = RandomForestRegressor(random_state=42)\n",
        "model_single.fit(X_train, y_train)\n",
        "predictions_single = model_single.predict(X_test)\n",
        "\n",
        "mae_single = mean_absolute_error(y_test, predictions_single)\n",
        "print(f'Mean Absolute Error (Single Model): {mae_single}')"
      ],
      "metadata": {
        "id": "jmuM6YnNGXLF",
        "outputId": "0cf5e44e-5518-419a-f67c-10d648e3e276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (Single Model): 4.656124666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparisons\n",
        "\n",
        "## Vertical Partitioning\n",
        "- Splits features into two categories (network and user-related).\n",
        "- Useful when different sets of features require specialized models.\n",
        "- Challenges include managing dependencies between features.\n",
        "\n",
        "## Horizontal Partitioning\n",
        "- Splits data based on geography (Urban vs Rural).\n",
        "- Enables customized models for subsets with differing characteristics.\n",
        "- Challenges include potential underfitting if subsets are too small.\n",
        "\n",
        "Both notebooks highlight how partitioning can enhance computational efficiency and scalability by tailoring models to specific feature sets or data subsets."
      ],
      "metadata": {
        "id": "hienczutHmCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Industry-Oriented Analysis (30 Points)\n",
        "1. Based on your partitioning experiments:\n",
        "o Recommend scenarios where vertical partitioning is more effective.\n",
        "o Suggest situations better suited for horizontal partitioning.\n",
        "2. Prepare a concise report or presentation for a potential Qualcomm use case:\n",
        "- How can these techniques improve scalability and performance in 5G network optimization?\n",
        "- What challenges might arise in deployment, and how would you address them?"
      ],
      "metadata": {
        "id": "JVelBlJLH-rG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Industry-Oriented Analysis of Vertical and Horizontal Partitioning Techniques in AI Models**\n",
        "\n",
        "### **1. Recommendations Based on Partitioning Experiments**\n",
        "\n",
        "#### **Scenarios Where Vertical Partitioning Is More Effective**\n",
        "Vertical partitioning divides an AI model based on feature types, enabling specialized processing of distinct feature groups. This approach is most effective in scenarios where:\n",
        "- **Feature Heterogeneity**: The dataset has diverse feature groups representing unrelated or loosely coupled domains, such as network-related features (signal strength, traffic) and user-related features (user count, device type).\n",
        "- **Modular Development**: Separate teams can independently optimize different parts of the model, improving development speed and flexibility.\n",
        "- **Resource Allocation**: Compute resources for processing feature groups differ significantly, such as using GPUs for network data and CPUs for user behavior data.\n",
        "- **Explainability**: Vertical partitioning improves interpretability by isolating the impact of distinct feature groups on predictions.\n",
        "\n",
        "**Examples**:\n",
        "- In network latency prediction, vertical partitioning allows specialized sub-models for signal strength and user behavior, improving prediction accuracy.\n",
        "- Financial models that segregate market trends and consumer data for targeted decision-making.\n",
        "\n",
        "#### **Scenarios Where Horizontal Partitioning Is More Effective**\n",
        "Horizontal partitioning divides the dataset into subsets based on geographical or categorical distinctions, training separate models for each subset. It is ideal when:\n",
        "- **Data Segmentation**: Data exhibits significant variability across categories or regions, such as urban and rural cell towers.\n",
        "- **Localized Optimization**: Models can be fine-tuned to regional characteristics, improving accuracy and reducing prediction error.\n",
        "- **Scalability**: Distributing subsets across multiple nodes reduces computational load per model.\n",
        "- **Improved Adaptability**: Models can be updated or retrained independently for different subsets.\n",
        "\n",
        "**Examples**:\n",
        "- Wireless networks where urban and rural areas require different configurations for latency optimization.\n",
        "- Retail models where customer behavior differs between metropolitan and suburban locations.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Detailed Report: Potential Qualcomm Use Case**\n",
        "\n",
        "#### **Improving Scalability and Performance in 5G Network Optimization**\n",
        "\n",
        "##### **Overview**\n",
        "5G networks demand real-time optimization of parameters like latency, throughput, and resource allocation. The heterogeneous nature of network data (e.g., signal strength, traffic) and the geographic diversity of deployment environments make traditional monolithic AI models inefficient. Applying vertical and horizontal partitioning can address these challenges:\n",
        "\n",
        "##### **Vertical Partitioning for Feature Specialization**\n",
        "1. **Signal Processing Model**:\n",
        "   - Processes network-related features like signal strength and network traffic.\n",
        "   - Optimized using specialized algorithms or hardware (e.g., ASICs for signal data).\n",
        "\n",
        "2. **User Behavior Model**:\n",
        "   - Processes user-related features like device type and user count.\n",
        "   - Focuses on behavioral patterns to predict and mitigate congestion.\n",
        "\n",
        "3. **Combined Output**:\n",
        "   - The predictions from both models are merged for latency optimization.\n",
        "   - Ensures comprehensive and precise decision-making.\n",
        "\n",
        "**Advantages**:\n",
        "- Enhanced model accuracy by leveraging feature-specific optimization.\n",
        "- Better resource utilization by assigning tailored hardware to each model.\n",
        "\n",
        "##### **Horizontal Partitioning for Regional Customization**\n",
        "1. **Urban Model**:\n",
        "   - Trained on urban cell tower data.\n",
        "   - Optimized for high traffic and dense user environments.\n",
        "\n",
        "2. **Rural Model**:\n",
        "   - Trained on rural cell tower data.\n",
        "   - Addresses challenges like signal degradation and sparse users.\n",
        "\n",
        "**Advantages**:\n",
        "- Reduces overfitting to outlier data by focusing on regional patterns.\n",
        "- Facilitates parallel model training and deployment for faster scalability.\n",
        "\n",
        "##### **Quantifiable Benefits for Qualcomm**\n",
        "- **Reduced Latency**: Tailored optimizations for urban and rural areas.\n",
        "- **Improved Throughput**: Efficient handling of high-traffic zones.\n",
        "- **Scalability**: Enables Qualcomm to deploy solutions across diverse geographies with minimal retraining.\n",
        "\n",
        "#### **Challenges in Deployment and Mitigation Strategies**\n",
        "\n",
        "1. **Data Partitioning Overheads**:\n",
        "   - **Challenge**: Partitioning data and models may introduce initial computational and operational complexity.\n",
        "   - **Solution**: Develop automated pipelines for dataset segmentation and feature extraction.\n",
        "\n",
        "2. **Communication Overhead Between Sub-Models**:\n",
        "   - **Challenge**: Vertical partitioning requires efficient merging of sub-model outputs.\n",
        "   - **Solution**: Use low-latency protocols for sub-model communication and ensemble methods to combine predictions effectively.\n",
        "\n",
        "3. **Data Imbalance**:\n",
        "   - **Challenge**: Horizontal partitioning may lead to smaller datasets for some regions, reducing model robustness.\n",
        "   - **Solution**: Apply data augmentation techniques or transfer learning to bolster underrepresented subsets.\n",
        "\n",
        "4. **Hardware Constraints**:\n",
        "   - **Challenge**: Specialized hardware for sub-models may increase costs.\n",
        "   - **Solution**: Leverage cloud-based solutions for scalable hardware resources.\n",
        "\n",
        "5. **Model Maintenance**:\n",
        "   - **Challenge**: Multiple models require frequent updates and monitoring.\n",
        "   - **Solution**: Implement centralized monitoring systems with version control for seamless updates.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "Both vertical and horizontal partitioning are powerful techniques that, when applied strategically, can significantly enhance the scalability and performance of AI models for 5G network optimization. Qualcomm, as a leader in wireless technologies, can leverage these methods to deliver innovative solutions for next-generation networks. While challenges exist, careful planning and robust implementation strategies can mitigate risks, ensuring efficient and reliable deployments.\n",
        "\n"
      ],
      "metadata": {
        "id": "-B0MvLSeIgep"
      }
    }
  ]
}