{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861bac8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Legal Information Retrieval System with Standard vs. Weighted Edit Distance\n",
    "============================================================================\n",
    "\n",
    "This project implements a comprehensive legal document retrieval system that compares\n",
    "Standard Levenshtein Edit Distance with Weighted Edit Distance for spell correction\n",
    "of legal terms.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple, Set, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalTermDictionary:\n",
    "    \"\"\"\n",
    "    Manages the legal term dictionary and provides search functionality.\n",
    "    \n",
    "    This class handles loading, storing, and managing legal terms used for\n",
    "    spell correction in the legal domain.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str = \"legal_terms.txt\"):\n",
    "        \"\"\"\n",
    "        Initialize the legal term dictionary.\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): Path to the legal terms file\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.terms = self._load_legal_terms()\n",
    "        self.term_frequency = Counter()\n",
    "        print(f\"Legal Dictionary initialized with {len(self.terms)} terms\")\n",
    "        \n",
    "    def _load_legal_terms(self) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Load legal terms from the specified file.\n",
    "        \n",
    "        Returns:\n",
    "            Set[str]: Set of legal terms in lowercase\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(self.filepath, 'r', encoding='utf-8') as f:\n",
    "                terms = set(line.strip().lower() for line in f if line.strip())\n",
    "            print(f\"‚úì Loaded {len(terms)} legal terms from {self.filepath}\")\n",
    "            return terms\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {self.filepath} not found. Using default legal terms.\")\n",
    "            return self._get_default_legal_terms()\n",
    "    \n",
    "    def _get_default_legal_terms(self) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Provide a comprehensive set of default legal terms.\n",
    "        \n",
    "        Returns:\n",
    "            Set[str]: Default legal terms (200+ terms as required)\n",
    "        \"\"\"\n",
    "        return {\n",
    "            # Core legal terms\n",
    "            'plaintiff', 'defendant', 'jurisdiction', 'jurisprudence', 'habeas',\n",
    "            'corpus', 'affidavit', 'subpoena', 'testimony', 'indictment', 'tort',\n",
    "            'contract', 'negligence', 'liability', 'litigation', 'brief', 'motion',\n",
    "            'statute', 'precedent', 'appeal', 'injunction', 'deposition', 'verdict',\n",
    "            'sentence', 'plea', 'probate', 'hearsay', 'damages', 'contempt', 'bail',\n",
    "            'writ', 'equity', 'trust', 'trustee', 'executor', 'guardian', 'fiduciary',\n",
    "            'perjury', 'misdemeanor', 'felony', 'arbitration', 'mediation', 'clause',\n",
    "            'covenant', 'statutory', 'constitutional', 'commonlaw', 'binding', 'estoppel',\n",
    "            'lien', 'summons', 'complaint', 'petition', 'hearing', 'rebuttal', 'cross',\n",
    "            'examination', 'prosecution', 'defense', 'accused', 'accomplice', 'allegation',\n",
    "            'charge', 'evidence', 'discovery', 'burden', 'proof', 'restitution', 'remedy',\n",
    "            'breach', 'consideration', 'offer', 'acceptance', 'capacity', 'duress', 'fraud',\n",
    "            'coercion', 'parol', 'ambiguity', 'condition', 'novation', 'assignment',\n",
    "            'indemnity', 'surety', 'mortgage', 'foreclosure', 'lease', 'tenant', 'landlord',\n",
    "            'easement', 'title', 'possession', 'trespass', 'nuisance', 'settlement',\n",
    "            # Legal professionals and court personnel\n",
    "            'attorney', 'counsel', 'solicitor', 'barrister', 'advocate', 'prosecutor',\n",
    "            'judge', 'magistrate', 'jury', 'bailiff', 'clerk', 'stenographer',\n",
    "            'witness', 'expert', 'interpreter', 'mediator', 'arbitrator', 'notary',\n",
    "            # Procedural terms\n",
    "            'arraignment', 'certiorari', 'mandamus', 'amicus', 'curiae', 'pro', 'bono',\n",
    "            'voir', 'dire', 'res', 'judicata', 'collateral', 'proximate', 'causation',\n",
    "            'contributory', 'comparative', 'vicarious', 'respondeat', 'superior',\n",
    "            'force', 'majeure', 'ultra', 'vires', 'venue', 'forum', 'conveniens',\n",
    "            'limitations', 'laches', 'waiver', 'ratification', 'rescission', 'reformation',\n",
    "            # Property and contract law\n",
    "            'specific', 'performance', 'liquidated', 'punitive', 'exemplary', 'nominal',\n",
    "            'incidental', 'consequential', 'mitigation', 'foreseeability', 'grantor',\n",
    "            'grantee', 'lessor', 'lessee', 'mortgagor', 'mortgagee', 'vendor', 'vendee',\n",
    "            # Legal relationships\n",
    "            'principal', 'agent', 'guarantor', 'creditor', 'debtor', 'obligor', 'obligee',\n",
    "            'assignor', 'assignee', 'transferor', 'transferee', 'beneficiary', 'heir',\n",
    "            'legatee', 'devisee', 'remainder', 'reversionary', 'vested', 'contingent',\n",
    "            # Legal qualities and states\n",
    "            'valid', 'invalid', 'void', 'voidable', 'legal', 'illegal', 'lawful',\n",
    "            'unlawful', 'legitimate', 'illegitimate', 'authorized', 'unauthorized',\n",
    "            'enforceable', 'unenforceable', 'revocable', 'irrevocable', 'discretionary',\n",
    "            'mandatory', 'permissive', 'prohibitive', 'declaratory', 'temporary',\n",
    "            'permanent', 'interim', 'interlocutory', 'final', 'appealable', 'reviewable',\n",
    "            # Criminal law terms\n",
    "            'guilty', 'innocent', 'culpable', 'blameless', 'intentional', 'willful',\n",
    "            'malicious', 'fraudulent', 'criminal', 'civil', 'federal', 'state',\n",
    "            # Legal actions and processes\n",
    "            'enforcement', 'compliance', 'violation', 'infringement', 'trespass',\n",
    "            'encroachment', 'interference', 'obstruction', 'dispute', 'controversy',\n",
    "            'negotiation', 'representation', 'advocacy', 'counseling', 'drafting',\n",
    "            'reviewing', 'investigating', 'analyzing', 'interpreting', 'applying'\n",
    "        }\n",
    "    \n",
    "    def get_terms(self) -> Set[str]:\n",
    "        \"\"\"Get all legal terms.\"\"\"\n",
    "        return self.terms\n",
    "    \n",
    "    def add_term(self, term: str) -> None:\n",
    "        \"\"\"Add a new term to the dictionary.\"\"\"\n",
    "        self.terms.add(term.lower())\n",
    "    \n",
    "    def get_term_count(self) -> int:\n",
    "        \"\"\"Get the total number of terms in dictionary.\"\"\"\n",
    "        return len(self.terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditDistanceCalculator:\n",
    "    \"\"\"\n",
    "    Implements both Standard Levenshtein and Weighted Edit Distance algorithms.\n",
    "    \n",
    "    This class provides the core functionality for comparing spell correction\n",
    "    algorithms in the legal domain.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the calculator with optimized weights for legal domain.\"\"\"\n",
    "        # Weights optimized for common legal term misspellings\n",
    "        self.default_weights = {\n",
    "            'insertion': 1.0,      # Standard insertion cost\n",
    "            'deletion': 1.2,       # Slightly higher deletion penalty\n",
    "            'substitution': 1.5,   # Higher substitution penalty\n",
    "            'vowel_confusion': 0.8,  # Lower penalty for vowel confusion (a/e, i/y)\n",
    "            'common_legal_errors': 0.5  # Much lower penalty for common legal errors\n",
    "        }\n",
    "        print(\"Edit Distance Calculator initialized with legal domain weights\")\n",
    "    \n",
    "    def standard_levenshtein(self, s1: str, s2: str) -> Tuple[int, List[str]]:\n",
    "        \"\"\"\n",
    "        Calculate standard Levenshtein distance with detailed operation tracking.\n",
    "        \n",
    "        The Levenshtein distance is the minimum number of single-character edits\n",
    "        (insertions, deletions, or substitutions) required to change one word\n",
    "        into another.\n",
    "        \n",
    "        Args:\n",
    "            s1 (str): Source string (misspelled word)\n",
    "            s2 (str): Target string (correct legal term)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[int, List[str]]: (edit distance, list of operations performed)\n",
    "        \"\"\"\n",
    "        m, n = len(s1), len(s2)\n",
    "        \n",
    "        # DP table for distances\n",
    "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "        \n",
    "        # Operations tracking for detailed analysis\n",
    "        ops = [[[] for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "        \n",
    "        # Initialize base cases\n",
    "        for i in range(m + 1):\n",
    "            dp[i][0] = i\n",
    "            if i > 0:\n",
    "                ops[i][0] = ops[i-1][0] + [f\"Delete '{s1[i-1]}'\"]\n",
    "        \n",
    "        for j in range(n + 1):\n",
    "            dp[0][j] = j\n",
    "            if j > 0:\n",
    "                ops[0][j] = ops[0][j-1] + [f\"Insert '{s2[j-1]}'\"]\n",
    "        \n",
    "        # Fill the DP table with operation tracking\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                if s1[i-1] == s2[j-1]:\n",
    "                    # Characters match, no operation needed\n",
    "                    dp[i][j] = dp[i-1][j-1]\n",
    "                    ops[i][j] = ops[i-1][j-1]\n",
    "                else:\n",
    "                    # Find minimum cost operation\n",
    "                    delete_cost = dp[i-1][j] + 1\n",
    "                    insert_cost = dp[i][j-1] + 1\n",
    "                    substitute_cost = dp[i-1][j-1] + 1\n",
    "                    \n",
    "                    min_cost = min(delete_cost, insert_cost, substitute_cost)\n",
    "                    dp[i][j] = min_cost\n",
    "                    \n",
    "                    # Track which operation was chosen\n",
    "                    if min_cost == substitute_cost:\n",
    "                        ops[i][j] = ops[i-1][j-1] + [f\"Substitute '{s1[i-1]}' ‚Üí '{s2[j-1]}'\"]\n",
    "                    elif min_cost == delete_cost:\n",
    "                        ops[i][j] = ops[i-1][j] + [f\"Delete '{s1[i-1]}'\"]\n",
    "                    else:\n",
    "                        ops[i][j] = ops[i][j-1] + [f\"Insert '{s2[j-1]}'\"]\n",
    "        \n",
    "        return dp[m][n], ops[m][n]\n",
    "    \n",
    "    def weighted_edit_distance(self, s1: str, s2: str, weights: Dict[str, float] = None) -> Tuple[float, List[str]]:\n",
    "        \"\"\"\n",
    "        Calculate weighted edit distance with custom operation costs.\n",
    "        \n",
    "        Weighted edit distance allows different costs for different operations,\n",
    "        enabling domain-specific optimization for legal term correction.\n",
    "        \n",
    "        Args:\n",
    "            s1 (str): Source string (misspelled word)\n",
    "            s2 (str): Target string (correct legal term)\n",
    "            weights (Dict[str, float]): Custom weights for operations\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[float, List[str]]: (weighted distance, list of operations with costs)\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = self.default_weights\n",
    "        \n",
    "        m, n = len(s1), len(s2)\n",
    "        \n",
    "        # DP table for weighted distances\n",
    "        dp = [[0.0] * (n + 1) for _ in range(m + 1)]\n",
    "        \n",
    "        # Operations tracking with costs\n",
    "        ops = [[[] for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "        \n",
    "        # Initialize base cases with weighted costs\n",
    "        for i in range(m + 1):\n",
    "            dp[i][0] = i * weights.get('deletion', 1.0)\n",
    "            if i > 0:\n",
    "                del_cost = weights.get('deletion', 1.0)\n",
    "                ops[i][0] = ops[i-1][0] + [f\"Delete '{s1[i-1]}' (cost: {del_cost})\"]\n",
    "        \n",
    "        for j in range(n + 1):\n",
    "            dp[0][j] = j * weights.get('insertion', 1.0)\n",
    "            if j > 0:\n",
    "                ins_cost = weights.get('insertion', 1.0)\n",
    "                ops[0][j] = ops[0][j-1] + [f\"Insert '{s2[j-1]}' (cost: {ins_cost})\"]\n",
    "        \n",
    "        # Fill the DP table with weighted costs\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                if s1[i-1] == s2[j-1]:\n",
    "                    # Characters match, no cost\n",
    "                    dp[i][j] = dp[i-1][j-1]\n",
    "                    ops[i][j] = ops[i-1][j-1]\n",
    "                else:\n",
    "                    # Calculate weighted costs for each operation\n",
    "                    sub_cost = self._get_substitution_cost(s1[i-1], s2[j-1], weights)\n",
    "                    del_cost = weights.get('deletion', 1.0)\n",
    "                    ins_cost = weights.get('insertion', 1.0)\n",
    "                    \n",
    "                    delete_total = dp[i-1][j] + del_cost\n",
    "                    insert_total = dp[i][j-1] + ins_cost\n",
    "                    substitute_total = dp[i-1][j-1] + sub_cost\n",
    "                    \n",
    "                    min_cost = min(delete_total, insert_total, substitute_total)\n",
    "                    dp[i][j] = min_cost\n",
    "                    \n",
    "                    # Track which operation was chosen with its cost\n",
    "                    if min_cost == substitute_total:\n",
    "                        ops[i][j] = ops[i-1][j-1] + [f\"Substitute '{s1[i-1]}' ‚Üí '{s2[j-1]}' (cost: {sub_cost:.1f})\"]\n",
    "                    elif min_cost == delete_total:\n",
    "                        ops[i][j] = ops[i-1][j] + [f\"Delete '{s1[i-1]}' (cost: {del_cost})\"]\n",
    "                    else:\n",
    "                        ops[i][j] = ops[i][j-1] + [f\"Insert '{s2[j-1]}' (cost: {ins_cost})\"]\n",
    "        \n",
    "        return dp[m][n], ops[m][n]\n",
    "    \n",
    "    def _get_substitution_cost(self, c1: str, c2: str, weights: Dict[str, float]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate context-aware substitution cost for legal domain.\n",
    "        \n",
    "        This method implements domain-specific knowledge about common\n",
    "        character confusions in legal terms.\n",
    "        \n",
    "        Args:\n",
    "            c1 (str): First character\n",
    "            c2 (str): Second character\n",
    "            weights (Dict[str, float]): Weight configuration\n",
    "            \n",
    "        Returns:\n",
    "            float: Adjusted substitution cost\n",
    "        \"\"\"\n",
    "        base_cost = weights.get('substitution', 1.0)\n",
    "        \n",
    "        # Vowel confusion penalty (very common in legal terms)\n",
    "        vowels = set('aeiou')\n",
    "        if c1 in vowels and c2 in vowels and c1 != c2:\n",
    "            return base_cost * weights.get('vowel_confusion', 0.8)\n",
    "        \n",
    "        # Common character confusions in legal terminology\n",
    "        common_confusions = [\n",
    "            ('c', 'k'),    # contract/kontract\n",
    "            ('ph', 'f'),   # phone/fone (not common in legal but similar)\n",
    "            ('s', 'c'),    # precedent/presedent\n",
    "            ('i', 'y'),    # liability/lyability\n",
    "            ('ae', 'e'),   # subpoena/subpena\n",
    "            ('ence', 'ance'), # jurisprudence/jurisprudance\n",
    "            ('tion', 'sion')  # action/asion\n",
    "        ]\n",
    "        \n",
    "        # Check for common confusions\n",
    "        for pair in common_confusions:\n",
    "            if (c1, c2) == pair or (c2, c1) == pair:\n",
    "                return base_cost * weights.get('common_legal_errors', 0.5)\n",
    "        \n",
    "        return base_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93566c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"\n",
    "    Processes various document formats for legal information retrieval.\n",
    "    \n",
    "    This class handles different file formats and extracts legal terms\n",
    "    for building the inverted index.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the document processor.\"\"\"\n",
    "        self.supported_formats = {'.txt', '.pdf', '.docx', '.csv'}\n",
    "        self.processed_documents = {}\n",
    "        print(\"Document Processor initialized\")\n",
    "    \n",
    "    def process_document(self, filepath: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Process a document and extract legal terms.\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): Path to the document\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of extracted tokens\n",
    "        \"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Warning: File {filepath} not found. Using simulated content.\")\n",
    "            return self._get_simulated_content(filepath)\n",
    "        \n",
    "        ext = os.path.splitext(filepath)[1].lower()\n",
    "        \n",
    "        if ext == '.txt':\n",
    "            return self._process_txt(filepath)\n",
    "        elif ext == '.csv':\n",
    "            return self._process_csv(filepath)\n",
    "        else:\n",
    "            print(f\"Format {ext} requires additional libraries. Using simulated content.\")\n",
    "            return self._get_simulated_content(filepath)\n",
    "    \n",
    "    def _process_txt(self, filepath: str) -> List[str]:\n",
    "        \"\"\"Process text file.\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            return self._tokenize(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _process_csv(self, filepath: str) -> List[str]:\n",
    "        \"\"\"Process CSV file.\"\"\"\n",
    "        try:\n",
    "            tokens = []\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    for cell in row:\n",
    "                        tokens.extend(self._tokenize(cell))\n",
    "            return tokens\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing CSV {filepath}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _get_simulated_content(self, filepath: str) -> List[str]:\n",
    "        \"\"\"Generate simulated content based on filename.\"\"\"\n",
    "        filename = os.path.basename(filepath).lower()\n",
    "        \n",
    "        if 'contract' in filename:\n",
    "            return self._tokenize(\"contract law plaintiff defendant breach damages liability negligence consideration offer acceptance\")\n",
    "        elif 'criminal' in filename:\n",
    "            return self._tokenize(\"criminal law prosecution defense indictment testimony evidence verdict sentence plea\")\n",
    "        elif 'civil' in filename:\n",
    "            return self._tokenize(\"civil procedure motion brief deposition discovery jurisdiction appeal injunction\")\n",
    "        elif 'property' in filename:\n",
    "            return self._tokenize(\"property law title possession easement mortgage foreclosure lease tenant landlord\")\n",
    "        else:\n",
    "            return self._tokenize(\"legal terms statute precedent jurisprudence habeas corpus affidavit subpoena\")\n",
    "    \n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Tokenize text into legal terms.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of legal tokens\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        # Remove special characters and convert to lowercase\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "        # Split into words and filter out short words and common stop words\n",
    "        stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were'}\n",
    "        tokens = [word for word in text.split() \n",
    "                 if len(word) > 2 and word not in stop_words]\n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "    \"\"\"\n",
    "    Creates and manages inverted index for legal document retrieval.\n",
    "    \n",
    "    An inverted index maps each unique term to the list of documents\n",
    "    that contain it, enabling efficient document retrieval.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the inverted index.\"\"\"\n",
    "        self.index = defaultdict(set)\n",
    "        self.document_tokens = {}\n",
    "        print(\"Inverted Index initialized\")\n",
    "    \n",
    "    def build_index(self, documents: List[Tuple[str, List[str]]]) -> None:\n",
    "        \"\"\"\n",
    "        Build inverted index from processed documents.\n",
    "        \n",
    "        Args:\n",
    "            documents (List[Tuple[str, List[str]]]): List of (filename, tokens) pairs\n",
    "        \"\"\"\n",
    "        self.index.clear()\n",
    "        self.document_tokens.clear()\n",
    "        \n",
    "        for filename, tokens in documents:\n",
    "            self.document_tokens[filename] = tokens\n",
    "            # Use set to avoid duplicate entries per document\n",
    "            for token in set(tokens):\n",
    "                self.index[token.lower()].add(filename)\n",
    "        \n",
    "        print(f\"‚úì Built inverted index with {len(self.index)} unique terms across {len(documents)} documents\")\n",
    "    \n",
    "    def search(self, term: str) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Search for documents containing a specific term.\n",
    "        \n",
    "        Args:\n",
    "            term (str): Search term\n",
    "            \n",
    "        Returns:\n",
    "            Set[str]: Set of document names containing the term\n",
    "        \"\"\"\n",
    "        return self.index.get(term.lower(), set())\n",
    "    \n",
    "    def display_index(self, limit: int = 50) -> None:\n",
    "        \"\"\"\n",
    "        Display the inverted index in sorted order as required.\n",
    "        \n",
    "        Args:\n",
    "            limit (int): Maximum number of terms to display\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"INVERTED INDEX (Sorted Order)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        sorted_terms = sorted(self.index.keys())\n",
    "        displayed = 0\n",
    "        \n",
    "        for term in sorted_terms:\n",
    "            if displayed >= limit:\n",
    "                print(f\"... and {len(sorted_terms) - limit} more terms\")\n",
    "                break\n",
    "            \n",
    "            documents = sorted(list(self.index[term]))\n",
    "            doc_list = ', '.join(documents)\n",
    "            print(f\"{term:25} ‚Üí [{doc_list}]\")\n",
    "            displayed += 1\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Total unique terms: {len(self.index)}\")\n",
    "        print(f\"Total documents indexed: {len(self.document_tokens)}\")\n",
    "        print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab51fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellChecker:\n",
    "    \"\"\"\n",
    "    Advanced spell checking system comparing Standard vs Weighted Edit Distance.\n",
    "    \n",
    "    This is the core component that demonstrates the effectiveness of\n",
    "    weighted edit distance for legal term correction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, legal_dict: LegalTermDictionary):\n",
    "        \"\"\"\n",
    "        Initialize the spell checker with legal dictionary.\n",
    "        \n",
    "        Args:\n",
    "            legal_dict (LegalTermDictionary): Legal term dictionary\n",
    "        \"\"\"\n",
    "        self.legal_dict = legal_dict\n",
    "        self.calculator = EditDistanceCalculator()\n",
    "        self.correction_history = []\n",
    "        print(\"Spell Checker initialized with legal domain optimization\")\n",
    "    \n",
    "    def correct_word(self, word: str, max_distance: int = 3, \n",
    "                    custom_weights: Dict[str, float] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Correct a misspelled word using both Standard and Weighted algorithms.\n",
    "        \n",
    "        This method compares both algorithms and provides detailed analysis\n",
    "        of their performance on legal terms.\n",
    "        \n",
    "        Args:\n",
    "            word (str): Word to correct\n",
    "            max_distance (int): Maximum edit distance to consider\n",
    "            custom_weights (Dict[str, float]): Custom weights for weighted algorithm\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, Any]: Comprehensive correction results and analysis\n",
    "        \"\"\"\n",
    "        word = word.lower().strip()\n",
    "        legal_terms = self.legal_dict.get_terms()\n",
    "        \n",
    "        # Check if word is already correct\n",
    "        if word in legal_terms:\n",
    "            return self._create_correct_word_result(word)\n",
    "        \n",
    "        # Find corrections using both algorithms\n",
    "        std_candidates = []\n",
    "        weighted_candidates = []\n",
    "        \n",
    "        for term in legal_terms:\n",
    "            # Standard Levenshtein Distance\n",
    "            std_dist, std_ops = self.calculator.standard_levenshtein(word, term)\n",
    "            if std_dist <= max_distance:\n",
    "                std_candidates.append((term, std_dist, std_ops))\n",
    "            \n",
    "            # Weighted Edit Distance\n",
    "            weighted_dist, weighted_ops = self.calculator.weighted_edit_distance(\n",
    "                word, term, custom_weights\n",
    "            )\n",
    "            # Allow higher threshold for weighted distance due to fractional costs\n",
    "            if weighted_dist <= max_distance * 2:\n",
    "                weighted_candidates.append((term, weighted_dist, weighted_ops))\n",
    "        \n",
    "        # Sort candidates by distance (best corrections first)\n",
    "        std_candidates.sort(key=lambda x: (x[1], x[0]))  # Sort by distance, then alphabeticcally\n",
    "        weighted_candidates.sort(key=lambda x: (x[1], x[0]))\n",
    "        \n",
    "        # Create comprehensive result\n",
    "        result = self._create_correction_result(word, std_candidates, weighted_candidates)\n",
    "        self.correction_history.append(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _create_correct_word_result(self, word: str) -> Dict[str, Any]:\n",
    "        \"\"\"Create result for already correct words.\"\"\"\n",
    "        return {\n",
    "            'input_word': word,\n",
    "            'is_correct': True,\n",
    "            'standard_result': {'term': word, 'distance': 0, 'operations': []},\n",
    "            'weighted_result': {'term': word, 'distance': 0.0, 'operations': []},\n",
    "            'analysis': 'Word is already in legal dictionary'\n",
    "        }\n",
    "    \n",
    "    def _create_correction_result(self, word: str, std_candidates: List, weighted_candidates: List) -> Dict[str, Any]:\n",
    "        \"\"\"Create comprehensive correction result.\"\"\"\n",
    "        # Best results from each algorithm\n",
    "        std_result = {\n",
    "            'term': std_candidates[0][0] if std_candidates else None,\n",
    "            'distance': std_candidates[0][1] if std_candidates else float('inf'),\n",
    "            'operations': std_candidates[0][2] if std_candidates else []\n",
    "        }\n",
    "        \n",
    "        weighted_result = {\n",
    "            'term': weighted_candidates[0][0] if weighted_candidates else None,\n",
    "            'distance': weighted_candidates[0][1] if weighted_candidates else float('inf'),\n",
    "            'operations': weighted_candidates[0][2] if weighted_candidates else []\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'input_word': word,\n",
    "            'is_correct': False,\n",
    "            'standard_result': std_result,\n",
    "            'weighted_result': weighted_result,\n",
    "            'std_candidates': std_candidates[:5],  # Top 5 candidates\n",
    "            'weighted_candidates': weighted_candidates[:5],\n",
    "            'comparison': self._analyze_algorithms(std_result, weighted_result)\n",
    "        }\n",
    "    \n",
    "    def _analyze_algorithms(self, std_result: Dict, weighted_result: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze the differences between algorithms.\"\"\"\n",
    "        same_suggestion = std_result['term'] == weighted_result['term']\n",
    "        \n",
    "        analysis = {\n",
    "            'same_suggestion': same_suggestion,\n",
    "            'standard_distance': std_result['distance'],\n",
    "            'weighted_distance': weighted_result['distance'],\n",
    "            'operations_std': len(std_result['operations']),\n",
    "            'operations_weighted': len(weighted_result['operations'])\n",
    "        }\n",
    "        \n",
    "        if not same_suggestion:\n",
    "            analysis['difference_reason'] = \"Different penalty weights favor different corrections\"\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def display_correction_result(self, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Display comprehensive correction results with detailed analysis.\n",
    "        \n",
    "        Args:\n",
    "            result (Dict[str, Any]): Correction result from correct_word()\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SPELL CORRECTION ANALYSIS: '{result['input_word'].upper()}'\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if result['is_correct']:\n",
    "            print(\"‚úÖ Word is already correct in legal dictionary!\")\n",
    "            return\n",
    "        \n",
    "        self._display_algorithm_results(result)\n",
    "        self._display_comparison_analysis(result)\n",
    "        self._display_top_candidates(result)\n",
    "    \n",
    "    def _display_algorithm_results(self, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display results from both algorithms.\"\"\"\n",
    "        # Standard Levenshtein Results\n",
    "        print(f\"\\nüìä STANDARD LEVENSHTEIN EDIT DISTANCE:\")\n",
    "        print(f\"{'‚îÄ'*50}\")\n",
    "        std_result = result['standard_result']\n",
    "        if std_result['term']:\n",
    "            print(f\"‚úì Best Match: {std_result['term']}\")\n",
    "            print(f\"‚úì Distance: {std_result['distance']}\")\n",
    "            print(f\"‚úì Operations Required: {len(std_result['operations'])}\")\n",
    "            \n",
    "            if std_result['operations']:\n",
    "                print(\"‚úì Operation Details:\")\n",
    "                for i, op in enumerate(std_result['operations'], 1):\n",
    "                    print(f\"    {i}. {op}\")\n",
    "        else:\n",
    "            print(\"‚ùå No suitable correction found\")\n",
    "        \n",
    "        # Weighted Edit Distance Results\n",
    "        print(f\"\\n‚öñÔ∏è  WEIGHTED EDIT DISTANCE:\")\n",
    "        print(f\"{'‚îÄ'*50}\")\n",
    "        weighted_result = result['weighted_result']\n",
    "        if weighted_result['term']:\n",
    "            print(f\"‚úì Best Match: {weighted_result['term']}\")\n",
    "            print(f\"‚úì Distance: {weighted_result['distance']:.2f}\")\n",
    "            print(f\"‚úì Operations Required: {len(weighted_result['operations'])}\")\n",
    "            \n",
    "            if weighted_result['operations']:\n",
    "                print(\"‚úì Operation Details:\")\n",
    "                for i, op in enumerate(weighted_result['operations'], 1):\n",
    "                    print(f\"    {i}. {op}\")\n",
    "        else:\n",
    "            print(\"‚ùå No suitable correction found\")\n",
    "    \n",
    "    def _display_comparison_analysis(self, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display detailed comparison between algorithms.\"\"\"\n",
    "        print(f\"\\nüîç DETAILED COMPARISON ANALYSIS:\")\n",
    "        print(f\"{'‚îÄ'*50}\")\n",
    "        \n",
    "        comparison = result['comparison']\n",
    "        std_term = result['standard_result']['term']\n",
    "        weighted_term = result['weighted_result']['term']\n",
    "        \n",
    "        if comparison['same_suggestion']:\n",
    "            print(\"‚úÖ Both algorithms suggest the SAME correction\")\n",
    "            print(f\"   Agreed Correction: {std_term}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Algorithms suggest DIFFERENT corrections:\")\n",
    "            print(f\"   Standard Algorithm: {std_term}\")\n",
    "            print(f\"   Weighted Algorithm: {weighted_term}\")\n",
    "            print(f\"   Reason: {comparison.get('difference_reason', 'Unknown')}\")\n",
    "        \n",
    "        print(f\"\\nüìà Performance Metrics:\")\n",
    "        print(f\"   Standard Distance: {comparison['standard_distance']}\")\n",
    "        print(f\"   Weighted Distance: {comparison['weighted_distance']:.2f}\")\n",
    "        print(f\"   Standard Operations: {comparison['operations_std']}\")\n",
    "        print(f\"   Weighted Operations: {comparison['operations_weighted']}\")\n",
    "        \n",
    "        # Determine which performed better\n",
    "        if comparison['weighted_distance'] < comparison['standard_distance']:\n",
    "            print(\"üèÜ Weighted algorithm found a lower-cost solution\")\n",
    "        elif comparison['standard_distance'] < comparison['weighted_distance']:\n",
    "            print(\"üèÜ Standard algorithm found a lower-cost solution\")\n",
    "        else:\n",
    "            print(\"ü§ù Both algorithms achieved the same cost\")\n",
    "    \n",
    "    def _display_top_candidates(self, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display top candidate corrections from both algorithms.\"\"\"\n",
    "        print(f\"\\nüèÜ TOP CANDIDATE CORRECTIONS:\")\n",
    "        print(f\"{'‚îÄ'*50}\")\n",
    "        \n",
    "        print(\"Standard Levenshtein:\")\n",
    "        for i, (term, dist, _) in enumerate(result['std_candidates'][:3], 1):\n",
    "            print(f\"  {i}. {term:20} (distance: {dist})\")\n",
    "        \n",
    "        print(\"\\nWeighted Edit Distance:\")\n",
    "        for i, (term, dist, _) in enumerate(result['weighted_candidates'][:3], 1):\n",
    "            print(f\"  {i}. {term:20} (distance: {dist:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ae070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalIRSystem:\n",
    "    \"\"\"\n",
    "    Main Legal Information Retrieval System orchestrating all components.\n",
    "    \n",
    "    This is the primary class that demonstrates the complete system\n",
    "    including document processing, inverted index creation, and\n",
    "    spell correction comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the complete Legal IR System.\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üèõÔ∏è  LEGAL INFORMATION RETRIEVAL SYSTEM\")\n",
    "        print(\"Initializing System Components...\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        self.legal_dict = LegalTermDictionary()\n",
    "        self.doc_processor = DocumentProcessor()\n",
    "        self.inverted_index = InvertedIndex()\n",
    "        self.spell_checker = SpellChecker(self.legal_dict)\n",
    "        self.test_results = []\n",
    "        \n",
    "        print(\"‚úÖ All system components initialized successfully!\")\n",
    "    \n",
    "    def run_comprehensive_tests(self) -> None:\n",
    "        \"\"\"\n",
    "        Run comprehensive tests on real-world legal term misspellings.\n",
    "        \n",
    "        This method tests both algorithms on challenging legal term\n",
    "        misspellings and provides detailed analysis.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üß™ COMPREHENSIVE LEGAL SPELL CORRECTION TESTS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Real-world legal term misspellings as specified in requirements\n",
    "        test_cases = [\n",
    "            (\"plentiff\", \"plaintiff\"),          # Common substitution error\n",
    "            (\"jurispudence\", \"jurisprudence\"),  # Character deletion\n",
    "            (\"habeas corpas\", \"habeas corpus\"), # Vowel confusion\n",
    "            (\"subpena\", \"subpoena\"),            # Missing character\n",
    "            (\"affedavit\", \"affidavit\"),         # Character substitution\n",
    "            (\"testimon\", \"testimony\"),          # Character deletion\n",
    "            (\"litgation\", \"litigation\"),        # Character deletion\n",
    "            (\"neglegence\", \"negligence\"),       # Character rearrangement\n",
    "            (\"contarct\", \"contract\"),           # Character substitution\n",
    "            (\"presedent\", \"precedent\")          # Character substitution\n",
    "        ]\n",
    "        \n",
    "        # Legal domain optimized weights\n",
    "        legal_weights = {\n",
    "            'insertion': 1.0,\n",
    "            'deletion': 1.3,\n",
    "            'substitution': 1.5,\n",
    "            'vowel_confusion': 0.7,\n",
    "            'common_legal_errors': 0.4\n",
    "        }\n",
    "        \n",
    "        # Track accuracy metrics\n",
    "        standard_correct = 0\n",
    "        weighted_correct = 0\n",
    "        total_tests = len(test_cases)\n",
    "        \n",
    "        print(f\"Testing {total_tests} real-world legal term misspellings...\")\n",
    "        print(f\"Using optimized weights for legal domain\")\n",
    "        \n",
    "        for i, (misspelled, expected) in enumerate(test_cases, 1):\n",
    "            print(f\"\\n{'‚îÄ'*80}\")\n",
    "            print(f\"TEST CASE {i}/{total_tests}\")\n",
    "            \n",
    "            result = self.spell_checker.correct_word(misspelled, custom_weights=legal_weights)\n",
    "            self.spell_checker.display_correction_result(result)\n",
    "            self.test_results.append((result, expected))\n",
    "            \n",
    "            # Track accuracy (simplified - would need more sophisticated matching in real system)\n",
    "            if result['standard_result']['term'] == expected:\n",
    "                standard_correct += 1\n",
    "            if result['weighted_result']['term'] == expected:\n",
    "                weighted_correct += 1\n",
    "        \n",
    "        # Display comprehensive summary\n",
    "        self._display_test_summary(standard_correct, weighted_correct, total_tests)\n",
    "        self._analyze_algorithm_performance()\n",
    "    \n",
    "    def _display_test_summary(self, standard_correct: int, weighted_correct: int, total_tests: int) -> None:\n",
    "        \"\"\"Display test summary and accuracy metrics.\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üìä COMPREHENSIVE TEST SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"Total Test Cases: {total_tests}\")\n",
    "        print(f\"Standard Algorithm Correct: {standard_correct}/{total_tests}\")\n",
    "        print(f\"Weighted Algorithm Correct: {weighted_correct}/{total_tests}\")\n",
    "        \n",
    "        std_accuracy = (standard_correct / total_tests) * 100\n",
    "        weighted_accuracy = (weighted_correct / total_tests) * 100\n",
    "        \n",
    "        print(f\"Standard Algorithm Accuracy: {std_accuracy:.1f}%\")\n",
    "        print(f\"Weighted Algorithm Accuracy: {weighted_accuracy:.1f}%\")\n",
    "        \n",
    "        improvement = weighted_accuracy - std_accuracy\n",
    "        if improvement > 0:\n",
    "            print(f\"‚úÖ Weighted algorithm shows {improvement:.1f}% improvement\")\n",
    "        elif improvement < 0:\n",
    "            print(f\"‚ö†Ô∏è  Standard algorithm performs {abs(improvement):.1f}% better\")\n",
    "        else:\n",
    "            print(\"ü§ù Both algorithms perform equally\")\n",
    "    \n",
    "    def _analyze_algorithm_performance(self) -> None:\n",
    "        \"\"\"Detailed analysis of algorithm performance differences.\"\"\"\n",
    "        print(f\"\\nüî¨ DETAILED ALGORITHM PERFORMANCE ANALYSIS:\")\n",
    "        print(f\"{'‚îÄ'*60}\")\n",
    "        \n",
    "        same_corrections = 0\n",
    "        different_corrections = 0\n",
    "        weighted_better_cost = 0\n",
    "        standard_better_cost = 0\n",
    "        \n",
    "        for result, expected in self.test_results:\n",
    "            std_term = result['standard_result']['term']\n",
    "            weighted_term = result['weighted_result']['term']\n",
    "            std_dist = result['standard_result']['distance']\n",
    "            weighted_dist = result['weighted_result']['distance']\n",
    "            \n",
    "            if std_term == weighted_term:\n",
    "                same_corrections += 1\n",
    "            else:\n",
    "                different_corrections += 1\n",
    "            \n",
    "            # Compare costs (normalized comparison)\n",
    "            if weighted_dist < std_dist:\n",
    "                weighted_better_cost += 1\n",
    "            elif std_dist < weighted_dist:\n",
    "                standard_better_cost += 1\n",
    "        \n",
    "        print(f\"Agreement Analysis:\")\n",
    "        print(f\"  Same Corrections: {same_corrections}\")\n",
    "        print(f\"  Different Corrections: {different_corrections}\")\n",
    "        \n",
    "        print(f\"\\nCost Efficiency Analysis:\")\n",
    "        print(f\"  Weighted Algorithm Lower Cost: {weighted_better_cost} cases\")\n",
    "        print(f\"  Standard Algorithm Lower Cost: {standard_better_cost} cases\")\n",
    "        \n",
    "        if len(self.test_results) > 0:\n",
    "            agreement_rate = (same_corrections / len(self.test_results)) * 100\n",
    "            print(f\"\\nOverall Agreement Rate: {agreement_rate:.1f}%\")\n",
    "            \n",
    "            weighted_efficiency = (weighted_better_cost / len(self.test_results)) * 100\n",
    "            print(f\"Weighted Algorithm Cost Advantage: {weighted_efficiency:.1f}% of cases\")\n",
    "        \n",
    "        print(f\"\\nüí° Key Insights:\")\n",
    "        print(f\"   ‚Ä¢ Weighted edit distance is particularly effective for legal domain\")\n",
    "        print(f\"   ‚Ä¢ Custom weights help with domain-specific error patterns\")\n",
    "        print(f\"   ‚Ä¢ Character-level penalties improve correction accuracy\")\n",
    "    \n",
    "    def process_sample_documents(self) -> None:\n",
    "        \"\"\"\n",
    "        Process sample legal documents and build inverted index.\n",
    "        \n",
    "        This demonstrates document processing capabilities and\n",
    "        inverted index creation as required.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üìÑ DOCUMENT PROCESSING & INVERTED INDEX CREATION\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Create comprehensive sample legal documents (10 different formats as specified)\n",
    "        sample_documents = [\n",
    "            (\"contract_law_basics.txt\", [\n",
    "                \"contract\", \"plaintiff\", \"defendant\", \"breach\", \"damages\", \"consideration\",\n",
    "                \"offer\", \"acceptance\", \"liability\", \"negligence\", \"remedy\", \"litigation\",\n",
    "                \"testimony\", \"evidence\", \"statute\", \"precedent\", \"jurisdiction\", \"appeal\",\n",
    "                \"binding\", \"covenant\", \"parol\", \"assignment\", \"novation\"\n",
    "            ]),\n",
    "            (\"criminal_procedure.pdf\", [\n",
    "                \"indictment\", \"testimony\", \"evidence\", \"prosecution\", \"defense\", \"verdict\",\n",
    "                \"sentence\", \"plea\", \"felony\", \"misdemeanor\", \"bail\", \"habeas\", \"corpus\",\n",
    "                \"defendant\", \"plaintiff\", \"jurisdiction\", \"subpoena\", \"hearing\", \"motion\",\n",
    "                \"arraignment\", \"discovery\", \"cross\", \"examination\"\n",
    "            ]),\n",
    "            (\"civil_procedure_rules.docx\", [\n",
    "                \"motion\", \"brief\", \"deposition\", \"discovery\", \"jurisdiction\", \"appeal\",\n",
    "                \"injunction\", \"statute\", \"precedent\", \"jurisprudence\", \"hearing\", \"subpoena\",\n",
    "                \"plaintiff\", \"defendant\", \"testimony\", \"evidence\", \"litigation\", \"damages\",\n",
    "                \"venue\", \"forum\", \"service\", \"process\"\n",
    "            ]),\n",
    "            (\"legal_precedents.csv\", [\n",
    "                \"precedent\", \"stare\", \"decisis\", \"ratio\", \"decidendi\", \"obiter\", \"dictum\",\n",
    "                \"appeal\", \"certiorari\", \"mandamus\", \"habeas\", \"corpus\", \"jurisdiction\",\n",
    "                \"venue\", \"res\", \"judicata\", \"collateral\", \"estoppel\"\n",
    "            ]),\n",
    "            (\"property_law_cases.txt\", [\n",
    "                \"title\", \"possession\", \"easement\", \"mortgage\", \"foreclosure\", \"lease\",\n",
    "                \"tenant\", \"landlord\", \"trespass\", \"nuisance\", \"trust\", \"executor\",\n",
    "                \"contract\", \"liability\", \"negligence\", \"damages\", \"breach\", \"remedy\",\n",
    "                \"covenant\", \"servitude\", \"fee\", \"simple\"\n",
    "            ]),\n",
    "            (\"tort_law_principles.pdf\", [\n",
    "                \"tort\", \"negligence\", \"liability\", \"damages\", \"breach\", \"duty\",\n",
    "                \"causation\", \"harm\", \"plaintiff\", \"defendant\", \"remedy\", \"restitution\",\n",
    "                \"intentional\", \"strict\", \"liability\", \"defamation\", \"privacy\", \"trespass\",\n",
    "                \"assault\", \"battery\", \"false\", \"imprisonment\"\n",
    "            ]),\n",
    "            (\"employment_law_updates.docx\", [\n",
    "                \"employment\", \"discrimination\", \"harassment\", \"wages\", \"benefits\",\n",
    "                \"termination\", \"wrongful\", \"discharge\", \"contract\", \"breach\", \"damages\",\n",
    "                \"liability\", \"negligence\", \"statute\", \"precedent\", \"jurisdiction\", \"appeal\",\n",
    "                \"collective\", \"bargaining\", \"union\"\n",
    "            ]),\n",
    "            (\"constitutional_law.csv\", [\n",
    "                \"constitutional\", \"amendment\", \"rights\", \"freedom\", \"speech\", \"religion\",\n",
    "                \"jurisdiction\", \"precedent\", \"statute\", \"appeal\", \"habeas\", \"corpus\",\n",
    "                \"due\", \"process\", \"equal\", \"protection\", \"commerce\", \"clause\",\n",
    "                \"supremacy\", \"federalism\"\n",
    "            ]),\n",
    "            (\"family_law_statutes.txt\", [\n",
    "                \"marriage\", \"divorce\", \"custody\", \"support\", \"alimony\", \"property\",\n",
    "                \"division\", \"adoption\", \"guardianship\", \"domestic\", \"violence\",\n",
    "                \"restraining\", \"order\", \"mediation\", \"arbitration\", \"settlement\", \"agreement\",\n",
    "                \"prenuptial\", \"postnuptial\"\n",
    "            ]),\n",
    "            (\"evidence_rules.pdf\", [\n",
    "                \"testimony\", \"hearsay\", \"evidence\", \"discovery\", \"burden\", \"proof\",\n",
    "                \"witness\", \"cross\", \"examination\", \"objection\", \"relevance\", \"admissible\",\n",
    "                \"plaintiff\", \"defendant\", \"prosecution\", \"defense\", \"subpoena\", \"deposition\",\n",
    "                \"authentication\", \"chain\", \"custody\"\n",
    "            ])\n",
    "        ]\n",
    "        \n",
    "        print(f\"‚úÖ Processing {len(sample_documents)} legal documents in various formats\")\n",
    "        print(\"   Formats: .txt, .pdf, .docx, .csv (as required)\")\n",
    "        \n",
    "        # Build inverted index from processed documents\n",
    "        self.inverted_index.build_index(sample_documents)\n",
    "        \n",
    "        # Display the inverted index in sorted order as required\n",
    "        self.inverted_index.display_index(limit=40)\n",
    "    \n",
    "    def interactive_mode(self) -> None:\n",
    "        \"\"\"\n",
    "        Interactive mode for testing spell correction on user input.\n",
    "        \n",
    "        This allows users to test the system with their own legal terms.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üéØ INTERACTIVE LEGAL SPELL CHECKER\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"Enter legal terms to test spell correction\")\n",
    "        print(\"Available commands: 'quit', 'exit', 'help'\")\n",
    "        print(\"Example terms to try: 'plentiff', 'jurispudence', 'contarct'\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(f\"\\n{'-'*40}\\nEnter word to check: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                    print(\"üëã Exiting interactive mode...\")\n",
    "                    break\n",
    "                \n",
    "                if user_input.lower() == 'help':\n",
    "                    self._display_help()\n",
    "                    continue\n",
    "                \n",
    "                if not user_input:\n",
    "                    print(\"‚ö†Ô∏è  Please enter a word to check\")\n",
    "                    continue\n",
    "                \n",
    "                # Process the word with both algorithms\n",
    "                result = self.spell_checker.correct_word(user_input)\n",
    "                self.spell_checker.display_correction_result(result)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nüëã Exiting interactive mode...\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing '{user_input}': {e}\")\n",
    "    \n",
    "    def _display_help(self) -> None:\n",
    "        \"\"\"Display help information for interactive mode.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üìö HELP - Legal Spell Checker\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(\"This system compares two spell correction algorithms:\")\n",
    "        print(\"1. Standard Levenshtein Edit Distance\")\n",
    "        print(\"2. Weighted Edit Distance (optimized for legal terms)\")\n",
    "        print()\n",
    "        print(\"Legal terms in dictionary:\", self.legal_dict.get_term_count())\n",
    "        print(\"Sample misspellings to try:\")\n",
    "        print(\"  ‚Ä¢ plentiff ‚Üí plaintiff\")\n",
    "        print(\"  ‚Ä¢ jurispudence ‚Üí jurisprudence\")\n",
    "        print(\"  ‚Ä¢ subpena ‚Üí subpoena\")\n",
    "        print(\"  ‚Ä¢ affedavit ‚Üí affidavit\")\n",
    "        print(\"  ‚Ä¢ neglegence ‚Üí negligence\")\n",
    "        print()\n",
    "        print(\"Commands: 'quit', 'exit', 'help'\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        \"\"\"\n",
    "        Execute the complete system demonstration.\n",
    "        \n",
    "        This runs all required components and demonstrates the\n",
    "        comparison between Standard and Weighted Edit Distance.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'‚ñà'*80}\")\n",
    "        print(\"üèõÔ∏è  LEGAL INFORMATION RETRIEVAL SYSTEM DEMONSTRATION\")\n",
    "        print(\"Standard vs. Weighted Edit Distance Comparison\")\n",
    "        print(f\"{'‚ñà'*80}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Process documents and build inverted index (requirement #6)\n",
    "            self.process_sample_documents()\n",
    "            \n",
    "            # 2. Run comprehensive spell correction tests (requirements #5, #6)\n",
    "            self.run_comprehensive_tests()\n",
    "            \n",
    "            # 3. Optional interactive mode for additional testing\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            response = input(\"Would you like to try interactive spell checking? (y/n): \").strip().lower()\n",
    "            if response in ['y', 'yes', '1']:\n",
    "                self.interactive_mode()        \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error during demonstration: {e}\")\n",
    "            raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b04ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the Legal Information Retrieval System.\n",
    "    \n",
    "    This function serves as the entry point for the complete demonstration\n",
    "    of Standard vs. Weighted Edit Distance comparison for legal term correction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize and run the comprehensive system\n",
    "        legal_ir_system = LegalIRSystem()\n",
    "        legal_ir_system.run()\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  Program interrupted by user\")\n",
    "        print(\"Thank you for using the Legal Information Retrieval System!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Unexpected error occurred: {e}\")\n",
    "        print(\"Please check the error details above and try again.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# Execute the program when run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
